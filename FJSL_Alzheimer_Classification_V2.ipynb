{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import shutil\n",
    "import os\n",
    " \n",
    "FILE_NAME = \"Data.zip\"\n",
    " \n",
    "def copy_zip_file(src_path, dest_dir):\n",
    " \n",
    "    zip_filename = os.path.basename(src_path)\n",
    "    dest_path = os.path.join(dest_dir, zip_filename)\n",
    " \n",
    "    if not os.path.exists(src_path):\n",
    "        print(f\"Error: The file '{src_path}' does not exist.\")\n",
    "        return\n",
    " \n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    " \n",
    "    shutil.copy2(src_path, dest_path)\n",
    "    print(f\"'{zip_filename}' has been copied to '{dest_dir}'.\")\n",
    " \n",
    "source_path = \"/content/drive/MyDrive/\" + FILE_NAME\n",
    "destination_directory = \"/content\"\n",
    " \n",
    "copy_zip_file(source_path, destination_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!unzip Data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")\n",
    "\n",
    "print(f\"-> {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Mild Dementia, Files Found: 5002\n",
      "Class: Moderate Dementia, Files Found: 488\n",
      "Class: Non Demented, Files Found: 67222\n",
      "Class: Very mild Dementia, Files Found: 13725\n"
     ]
    }
   ],
   "source": [
    "# Define Paths\n",
    "dataset_dir = \"Data\"  # Root folder containing class folders\n",
    "# Adjust class names to match actual folder names\n",
    "classes = [\"Mild Dementia\", \"Moderate Dementia\", \"Non Demented\", \"Very mild Dementia\"]\n",
    "\n",
    "# Load Data with Correct Folder Names\n",
    "image_paths, labels = [], []\n",
    "for class_label, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    if not os.path.exists(class_dir):\n",
    "        print(f\"Error: Folder {class_dir} does not exist.\")\n",
    "        continue\n",
    "    files = glob.glob(f\"{class_dir}/*.jpg\")  # Adjust extension if needed\n",
    "    print(f\"Class: {class_name}, Files Found: {len(files)}\")  # Debug: Count files\n",
    "    for file_path in files:\n",
    "        image_paths.append(file_path)\n",
    "        labels.append(class_label)\n",
    "\n",
    "# Proceed with the pipeline if files are found\n",
    "if len(image_paths) == 0:\n",
    "    raise ValueError(\"No images found. Check dataset folder names or file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, testing and validation\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.3, random_state=42,stratify=labels) # suffle by default and straity labels \n",
    "test_paths, val_paths, test_labels, val_labels = train_test_split(test_paths, test_labels, test_size=0.5, random_state=42,stratify=test_labels) # suffle by default and straity labels\n",
    "# to keep the same class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution: Counter({2: 47055, 3: 9607, 0: 3501, 1: 342})\n",
      "Testing set class distribution: Counter({2: 10084, 3: 2059, 0: 750, 1: 73})\n",
      "Validation set class distribution: Counter({2: 10083, 3: 2059, 0: 751, 1: 73})\n"
     ]
    }
   ],
   "source": [
    "# Count classes in each split\n",
    "train_class_counts = Counter(train_labels)\n",
    "test_class_counts = Counter(test_labels)\n",
    "val_class_counts = Counter(val_labels)\n",
    "\n",
    "print(\"Training set class distribution:\", train_class_counts)\n",
    "print(\"Testing set class distribution:\", test_class_counts)\n",
    "print(\"Validation set class distribution:\", val_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance data using tomeklinks undersampling\n",
    "import cv2\n",
    "def load_image(path, image_size=(224, 224)):\n",
    "    img = cv2.imread(path)  # Read image\n",
    "    img_resized = cv2.resize(img, image_size)  # Resize to a fixed size\n",
    "    img_flattened = img_resized.flatten()  # Flatten image to 1D array\n",
    "    return img_flattened\n",
    "\n",
    "def load_images(image_paths, image_size=(224, 224)):\n",
    "    images = list(map(lambda path: load_image(path, image_size), image_paths))\n",
    "    return np.array(images)\n",
    "\n",
    "X = load_images(train_paths)\n",
    "# Initialize TomekLinks\n",
    "RandomUnderSampler = RandomUnderSampler()\n",
    "\n",
    "# Apply TomekLinks to the dataset\n",
    "train_paths_under, train_labels_under = RandomUnderSampler.fit_resample(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After undersampling, get the indices of the selected paths\n",
    "selected_indices = np.where(np.isin(train_paths_under, train_labels_under))[0]\n",
    "\n",
    "# Retrieve the corresponding paths\n",
    "train_paths_under = [train_paths[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = load_images(val_paths)\n",
    "val_paths_under, val_labels_under = RandomUnderSampler.fit_resample(X_val, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After undersampling, get the indices of the selected paths\n",
    "selected_indices = np.where(np.isin(val_paths_under, val_labels_under))[0]\n",
    "\n",
    "# Retrieve the corresponding paths\n",
    "val_paths_under = [val_paths[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution: Counter({0: 342, 1: 342, 2: 342, 3: 342})\n"
     ]
    }
   ],
   "source": [
    "train_class_counts = Counter(train_labels_under)\n",
    "print(\"Training set class distribution:\", train_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution: Counter({0: 73, 1: 73, 2: 73, 3: 73})\n"
     ]
    }
   ],
   "source": [
    "val_class_counts = Counter(val_labels_under)\n",
    "print(\"Training set class distribution:\", val_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mover as imagens para as pastas correspondentes\n",
    "# for image_path, label in zip(train_paths, train_labels):\n",
    "#     label_dir = os.path.join('train', str(label))\n",
    "#     os.makedirs(label_dir, exist_ok=True)\n",
    "#     shutil.copy(image_path, os.path.join(label_dir, os.path.basename(image_path)))\n",
    "\n",
    "# for image_path, label in zip(val_paths, val_labels):\n",
    "#     label_dir = os.path.join('val', str(label))\n",
    "#     os.makedirs(label_dir, exist_ok=True)\n",
    "#     shutil.copy(image_path, os.path.join(label_dir, os.path.basename(image_path)))\n",
    "\n",
    "# for image_path, label in zip(test_paths, test_labels):\n",
    "#     label_dir = os.path.join('test', str(label))\n",
    "#     os.makedirs(label_dir, exist_ok=True)\n",
    "#     shutil.copy(image_path, os.path.join(label_dir, os.path.basename(image_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_treino = \"train\"\n",
    "# path_validacao = \"val\"\n",
    "# path_teste = \"test\"\n",
    "# #Rescale data and create data generator instances\n",
    "# train_datagenerator = ImageDataGenerator(rescale=1/255.)\n",
    "# val_datagenerator = ImageDataGenerator(rescale=1/255.)\n",
    "# test_datagenerator = ImageDataGenerator(rescale=1/255.)\n",
    "# datagenerator_augmentation = ImageDataGenerator(rescale = 1/255.,\n",
    "#                                                       rotation_range=20, #rotate the image\n",
    "#                                                       zoom_range = 0.2,#zoom the image\n",
    "#                                                       width_shift_range=0.2, #shift the image horizontally\n",
    "#                                                       height_shift_range=0.2, #shift the image vertically\n",
    "#                                                       horizontal_flip=True, #flip the image on horizontal axis\n",
    "#                                                       vertical_flip=True, #flip the image on vertical axis\n",
    "#                                                       shear_range = 0.2) #Shear the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load data in from images and turn into batches\n",
    "# train_data = train_datagenerator.flow_from_directory(path_treino,\n",
    "#                                                      target_size=(224,224),\n",
    "#                                                      batch_size=32,\n",
    "#                                                      class_mode='categorical'\n",
    "#                                                     )\n",
    "# val_data = val_datagenerator.flow_from_directory(path_validacao,\n",
    "#                                                      target_size=(224,224),\n",
    "#                                                      batch_size=32,\n",
    "#                                                      class_mode='categorical'\n",
    "#                                                     )\n",
    "# test_data = test_datagenerator.flow_from_directory(path_teste,\n",
    "#                                                      target_size=(224,224),\n",
    "#                                                      batch_size=32,\n",
    "#                                                      class_mode='categorical'\n",
    "#                                                     )\n",
    "# train_data_augmented = datagenerator_augmentation.flow_from_directory(path_treino,\n",
    "#                                                                             target_size=(224,224),\n",
    "#                                                                             batch_size=32,\n",
    "#                                                                             class_mode='categorical',\n",
    "#                                                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "train_paths_under = np.array(train_paths_under)\n",
    "test_paths = np.array(test_paths)\n",
    "val_paths_under = np.array(val_paths_under)\n",
    "\n",
    "# One-hot encode the labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "train_labels_under = label_binarizer.fit_transform(train_labels_under)\n",
    "test_labels = label_binarizer.transform(test_labels)\n",
    "val_labels_under = label_binarizer.transform(val_labels_under)\n",
    "\n",
    "\n",
    "# Define the datagenerator\n",
    "datagenerator_augmentation = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "# Preprocess and load an image from path\n",
    "def preprocess_image_with_array(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))  # Load image and resize\n",
    "    img_array = img_to_array(img)\n",
    "    return img_array\n",
    "\n",
    "# Apply augmentation multiple times using ImageDataGenerator\n",
    "def augment_multiple_times_keras(image_path, label, num_times):\n",
    "    image = preprocess_image_with_array(image_path)\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    augmented_images = []\n",
    "\n",
    "    # Generate num_times augmentations\n",
    "    for _ in range(num_times):\n",
    "        augmented_img = next(datagenerator_augmentation.flow(image, batch_size=1))[0]\n",
    "        augmented_images.append((augmented_img, label))\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "# Load dataset and preprocess using ImageDataGenerator-compatible approach\n",
    "def load_dataset_keras(image_paths, labels):\n",
    "    dataset = []\n",
    "    for path, label in zip(image_paths, labels):\n",
    "        image = preprocess_image_with_array(path)\n",
    "        dataset.append((image, label, path))  # Include path here\n",
    "    return dataset\n",
    "\n",
    "# Augment dataset by class\n",
    "def filter_by_class(dataset, class_index):\n",
    "    return [(img, lbl, path) for img, lbl, path in dataset if np.argmax(lbl) == class_index]\n",
    "\n",
    "def augment_class(dataset, class_index, num_augments):\n",
    "    class_subset = filter_by_class(dataset, class_index)\n",
    "    augmented = []\n",
    "    for img, lbl, path in class_subset:  # Unpack the path here as well\n",
    "        augmented += augment_multiple_times_keras(path, lbl, num_augments)\n",
    "    return augmented\n",
    "\n",
    "# Preprocess entire dataset\n",
    "train_dataset_raw = load_dataset_keras(train_paths_under, train_labels_under)\n",
    "val_dataset_raw = load_dataset_keras(val_paths_under, val_labels_under)\n",
    "test_dataset_raw = load_dataset_keras(test_paths, test_labels)\n",
    "\n",
    "# Organize data\n",
    "class_2_train_augmented = augment_class(train_dataset_raw, 2, 2)\n",
    "class_3_train_augmented = augment_class(train_dataset_raw, 3, 2)\n",
    "class_0_train_augmented = augment_class(train_dataset_raw, 0, 2)\n",
    "class_1_train_augmented = augment_class(train_dataset_raw, 1, 2)\n",
    "\n",
    "final_train_dataset = (\n",
    "    class_2_train_augmented +\n",
    "    class_3_train_augmented +\n",
    "    class_0_train_augmented +\n",
    "    class_1_train_augmented\n",
    ")\n",
    "\n",
    "class_2_val_augmented = augment_class(val_dataset_raw, 2, 2)\n",
    "class_3_val_augmented = augment_class(val_dataset_raw, 3, 2)\n",
    "class_0_val_augmented = augment_class(val_dataset_raw, 0, 2)\n",
    "class_1_val_augmented = augment_class(val_dataset_raw, 1, 2)\n",
    "\n",
    "final_val_dataset = (\n",
    "    class_2_val_augmented +\n",
    "    class_3_val_augmented +\n",
    "    class_0_val_augmented +\n",
    "    class_1_val_augmented\n",
    ")\n",
    "\n",
    "final_test_dataset = test_dataset_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset class distribution:\n",
      "Class 0: 684 images\n",
      "Class 1: 684 images\n",
      "Class 2: 684 images\n",
      "Class 3: 684 images\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "label_counts = Counter()\n",
    "\n",
    "# Loop through dataset\n",
    "for _, lbl in final_train_dataset:\n",
    "    class_index = np.argmax(lbl)  # Directly apply np.argmax to the NumPy array\n",
    "    label_counts[class_index] += 1\n",
    "\n",
    "# Print class distribution\n",
    "print(\"Final dataset class distribution:\")\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    print(f\"Class {label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Loop through dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, lbl \u001b[38;5;129;01min\u001b[39;00m final_val_dataset:\n\u001b[0;32m----> 5\u001b[0m     class_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mlbl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m())  \u001b[38;5;66;03m# Convert one-hot to class index\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     label_val_counts[class_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print class distribution\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "label_val_counts = Counter()\n",
    "\n",
    "# Loop through dataset\n",
    "for _, lbl in final_val_dataset:\n",
    "    class_index = np.argmax(lbl.numpy())  # Convert one-hot to class index\n",
    "    label_val_counts[class_index] += 1\n",
    "\n",
    "# Print class distribution\n",
    "print(\"Final val dataset class distribution:\")\n",
    "for label, count in sorted(label_val_counts.items()):\n",
    "    print(f\"Class {label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "def create_cnn(num_classes=4):\n",
    "    model = keras.Sequential([\n",
    "        # Convolutional Block 1\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Flatten & Dense Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),  # Reduce overfitting\n",
    "        layers.Dense(num_classes, activation='softmax')  # Output layer\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 111, 111, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 54, 54, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 26, 26, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11075712  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,170,372\n",
      "Trainable params: 11,169,924\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "cnn_model = create_cnn()\n",
    "\n",
    "# Print model summary\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test dataset shape:\", final_test_dataset)\n",
    "print(\"Final dataset shape:\", final_train_dataset)\n",
    "print(\"Test dataset shape:\", final_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_images, train_labels = zip(*final_train_dataset)\n",
    "val_images, val_labels = zip(*final_val_dataset)\n",
    "\n",
    "train_images = tf.convert_to_tensor(np.array(train_images))\n",
    "train_labels = tf.convert_to_tensor(np.array(train_labels))\n",
    "\n",
    "val_images = tf.convert_to_tensor(np.array(val_images))\n",
    "val_labels = tf.convert_to_tensor(np.array(val_labels))\n",
    "\n",
    "final_train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "final_val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Batch the dataset\n",
    "train_dataset = final_train_dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = final_val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "cnn_model.fit(train_dataset, validation_data=val_dataset, epochs=10)\n",
    "#cnn_model.fit(final_dataset, epochs=10, steps_per_epoch=len(final_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in final_dataset.take(1):\n",
    "    print(img.shape, label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in preprocessed_dataset_val.take(1):\n",
    "    print(img.shape, label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(final_dataset))  # Shape of images\n",
    "print(np.array(preprocessed_dataset_val))  # Shape of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.array(final_dataset))  # Shape of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAUTIA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
